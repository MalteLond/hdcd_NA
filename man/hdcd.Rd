% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hdcd.R
\name{hdcd}
\alias{hdcd}
\title{Change Point Detection Algorithm}
\usage{
hdcd(x, method = NULL, optimizer = NULL, delta = NULL,
  lambda = NULL, loss_function = NULL, gain_function = NULL,
  best_split_function = NULL, cross_validation_function = NULL,
  model_selection_function = NULL, control = hdcd_control())
}
\arguments{
\item{x}{A design matrix}

\item{method}{The method used to find splits. One of \code{glasso}, or \code{custom}.}

\item{optimizer}{The optimizer used to find change points. Supply \code{line_search} for most reliable results and
\code{section_search} for a faster (OBS) approach.}

\item{delta}{The minimal relative segment length.}

\item{lambda}{A regularisation parameter for methods that require one.}

\item{loss_function}{A function with formal arguments \code{x} and possibly \code{lambda} that returns
some kind of training loss.}

\item{gain_function}{A function with formal arguments \code{x}, \code{start}, \code{end} and \code{lambda} that returns
a closure with argument \code{split_point}, that returns the gain after splitting the segment (\code{start}, \code{end}]
at \code{split_point} given data \code{x} and tuning parameter \code{lambda}.}

\item{cross_validation_function}{A function with formal arguments \code{x}, \code{start}, \code{end}, \code{lambda} and \code{folds} that returns
a list with arguments \code{cv_loss} and \code{lambda_opt}.}

\item{model_selection_function}{A function with formal arguments \code{x}, \code{start}, \code{split_point} and \code{end} that
returns a list with arguments \code{statistic}, a value that measures the significance of the split at \code{split_point}, and
\code{is_siginificant}, a boolean indicating whether the value returned for \code{statistic} is significant.}

\item{control}{An object of class \code{hdcd_control} as generated by \link{hdcd_control}.}

\item{get_best_split}{A function with formal arguments \code{x}, \code{start}, \code{end} and \code{split_candidates} that returns
a list with arguments \code{gain} and \code{best_split}, where gain is an array of length \code{nrow(x)} with possibly evaluations
of a gains curve or similar saved and \code{best_split} it the best element of \code{split_candidates} to split the interval 
(\code{start}, \code{end}].}

\item{lambda}{A tuning parameter used in the evaluation of the gain curve. If a \code{cross_validation_function} is supplied
it will used lambda as an initial guess and in the following the optimal value from cross-validation will be used frot the 
evaluation of the gain curve.}
}
\value{
A tree with the splitting structure of the binary segmentation algorithm. If some form of inner cross validation or model selection
was used, the estimated change points can be extracted via \link{get_change_points_from_tree}.

This is the main function to be called of the package. It estimates change points in \code{x}. Currently available methods are \code{glasso} and \code{custom}.
For \code{glasso} a loglikelihood based loss function is used to estimate the best split in a binary segmentation fashion. For the method \code{custom} an
individual loss, gain or best_split_function can be supplied to find change points. The best split in each step of BS is found using optimizer, which can be set
to be one of \code{line_search} or \code{section_search}. Line Search finds the maximum of the gains function by evaluating it at every
possible split. Section Search (also Optimistic Binary Search) makes use of the piecewise convex structure of the gains curve to find one of the local maxima with
approximately \code{log(n)} evaluations of the gain function. We encourage the use of Line Search whenever the
computational cost allows this and Section Search else.
}
\description{
Find change points in a design matrix
}
\examples{
hdcd(x, method = 'glasso', optimizer = 'line_search', delta = 0.1, lambda = 1, control = hdcd_control(glasso_NA_method = 'pairwise'))
}
